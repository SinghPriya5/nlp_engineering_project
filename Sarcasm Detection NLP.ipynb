{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21ef299-334d-4ab7-8399-423f493302be",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9a6666-964d-4ddb-8f0f-a5f39f7874e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\Priya\\Desktop\\NLP\\Sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab3eef3-cfef-4667-9d16-3f3950aa0f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>3463</td>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>3464</td>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>3465</td>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3466</td>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>3467</td>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3468 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              tweet  \\\n",
       "0              0  The only thing I got from college is a caffein...   \n",
       "1              1  I love it when professors draw a big question ...   \n",
       "2              2  Remember the hundred emails from companies whe...   \n",
       "3              3  Today my pop-pop told me I was not “forced” to...   \n",
       "4              4  @VolphanCarol @littlewhitty @mysticalmanatee I...   \n",
       "...          ...                                                ...   \n",
       "3463        3463  The population spike in Chicago in 9 months is...   \n",
       "3464        3464  You'd think in the second to last English clas...   \n",
       "3465        3465  I’m finally surfacing after a holiday to Scotl...   \n",
       "3466        3466  Couldn't be prouder today. Well done to every ...   \n",
       "3467        3467  Overheard as my 13 year old games with a frien...   \n",
       "\n",
       "      sarcastic  sarcasm  irony  satire  understatement  overstatement  \\\n",
       "0             1      0.0    1.0     0.0             0.0            0.0   \n",
       "1             1      1.0    0.0     0.0             0.0            0.0   \n",
       "2             1      0.0    1.0     0.0             0.0            0.0   \n",
       "3             1      1.0    0.0     0.0             0.0            0.0   \n",
       "4             1      1.0    0.0     0.0             0.0            0.0   \n",
       "...         ...      ...    ...     ...             ...            ...   \n",
       "3463          0      NaN    NaN     NaN             NaN            NaN   \n",
       "3464          0      NaN    NaN     NaN             NaN            NaN   \n",
       "3465          0      NaN    NaN     NaN             NaN            NaN   \n",
       "3466          0      NaN    NaN     NaN             NaN            NaN   \n",
       "3467          0      NaN    NaN     NaN             NaN            NaN   \n",
       "\n",
       "      rhetorical_question  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "...                   ...  \n",
       "3463                  NaN  \n",
       "3464                  NaN  \n",
       "3465                  NaN  \n",
       "3466                  NaN  \n",
       "3467                  NaN  \n",
       "\n",
       "[3468 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcbbc3c-9031-4cc6-9f7a-20ee77a22024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0     The only thing I got from college is a caffein...          1\n",
       "1     I love it when professors draw a big question ...          1\n",
       "2     Remember the hundred emails from companies whe...          1\n",
       "3     Today my pop-pop told me I was not “forced” to...          1\n",
       "4     @VolphanCarol @littlewhitty @mysticalmanatee I...          1\n",
       "...                                                 ...        ...\n",
       "3463  The population spike in Chicago in 9 months is...          0\n",
       "3464  You'd think in the second to last English clas...          0\n",
       "3465  I’m finally surfacing after a holiday to Scotl...          0\n",
       "3466  Couldn't be prouder today. Well done to every ...          0\n",
       "3467  Overheard as my 13 year old games with a frien...          0\n",
       "\n",
       "[3468 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['tweet','sarcastic']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758ebe46-6359-4597-a6fa-d6b56f7f8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priya\\AppData\\Local\\Temp\\ipykernel_828\\1379821321.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f390c30b-1328-4827-b0df-0f5e5c315e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcastic\n",
       "0  The only thing I got from college is a caffein...          1\n",
       "1  I love it when professors draw a big question ...          1\n",
       "2  Remember the hundred emails from companies whe...          1\n",
       "3  Today my pop-pop told me I was not “forced” to...          1\n",
       "4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b5355-3344-425d-9bf5-6ee3ce534175",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f77579-fa69-4cee-8e35-91a8b1135353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\priya\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\priya\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\priya\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56cfa0b9-2a47-41b7-982f-05fbc5205056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Priya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from contractions import fix  # To handle contractions like don't -> do not\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbda0c0-c6a4-4dc2-9c50-743776fd478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priya\\AppData\\Local\\Temp\\ipykernel_828\\3931230.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].apply(clean_text_advanced)\n"
     ]
    }
   ],
   "source": [
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text_advanced(text):\n",
    "    # Expand contractions\n",
    "    text = fix(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    # Remove excessive whitespaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(clean_text_advanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527d2cd5-6c75-43d9-8314-f93473e9957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing got college caffeine addiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love professor draw big question mark next ans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember hundred email company covid started g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today poppop told “ forced ” go college 🙃 okay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol littlewhitty mysticalmanatee also...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>population spike chicago 9 month ridiculous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>would think second last english class year pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>finally surfacing holiday scotland difficult d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>could prouder today well done every student go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>overheard 13 year old game friend smell like t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0                  thing got college caffeine addiction          1\n",
       "1     love professor draw big question mark next ans...          1\n",
       "2     remember hundred email company covid started g...          1\n",
       "3     today poppop told “ forced ” go college 🙃 okay...          1\n",
       "4     volphancarol littlewhitty mysticalmanatee also...          1\n",
       "...                                                 ...        ...\n",
       "3463        population spike chicago 9 month ridiculous          0\n",
       "3464  would think second last english class year pro...          0\n",
       "3465  finally surfacing holiday scotland difficult d...          0\n",
       "3466  could prouder today well done every student go...          0\n",
       "3467  overheard 13 year old game friend smell like t...          0\n",
       "\n",
       "[3467 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9b5b02-8305-46b9-99d6-1723a6e1556d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarcastic\n",
       "0    2600\n",
       "1     867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbbc58e-43b6-43c1-b840-bc3ad324859f",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba379a6-f442-4fc3-a35d-3bfc4c3d7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "roc=RandomOverSampler(random_state=42)\n",
    "\n",
    "X=df['tweet'].values.reshape(-1,1)\n",
    "y=df.sarcastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8395da8e-4cd0-43f0-aab0-cd80a6c5d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = oversampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73aa748b-4a59-42ca-beed-038e8095bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'tweet': X_balanced.flatten(), 'sarcastic': y_balanced})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d93c9f-da0c-4384-8863-ff643f34c7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing got college caffeine addiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love professor draw big question mark next ans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remember hundred email company covid started g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>today poppop told “ forced ” go college 🙃 okay...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volphancarol littlewhitty mysticalmanatee also...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>recovered repressed memory today working kuman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>ayeee officially “ even girl ” season 😛</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>tested egg drop apartment complex fell man ’ h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>thinking one obsessed 💔</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>funny phone start turning piece shit new iphon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic\n",
       "0                  thing got college caffeine addiction          1\n",
       "1     love professor draw big question mark next ans...          1\n",
       "2     remember hundred email company covid started g...          1\n",
       "3     today poppop told “ forced ” go college 🙃 okay...          1\n",
       "4     volphancarol littlewhitty mysticalmanatee also...          1\n",
       "...                                                 ...        ...\n",
       "5195  recovered repressed memory today working kuman...          1\n",
       "5196            ayeee officially “ even girl ” season 😛          1\n",
       "5197  tested egg drop apartment complex fell man ’ h...          1\n",
       "5198                            thinking one obsessed 💔          1\n",
       "5199  funny phone start turning piece shit new iphon...          1\n",
       "\n",
       "[5200 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04143ac5-b93c-4902-b65a-f7b56aa0ea99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarcastic\n",
       "1    2600\n",
       "0    2600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sarcastic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de562a1-13e2-422c-ab62-1aa6897b0b28",
   "metadata": {},
   "source": [
    "# Vectorization and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dddd40c1-1c82-4696-8ac1-e5fa880a1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ae931c6-99e1-43e9-afc3-faf90bd27082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4472f3a4-cf03-4ff3-9a59-a6e8a594db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf.fit_transform(df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dc8eae8-150f-47ab-8026-bc60b673b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ad1a5f9-b8f5-4f3e-a7cd-1cf038169217",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f3657f7-b20a-4ae9-83f6-529b3bac1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95630e05-3000-4478-9b38-443b76759459",
   "metadata": {},
   "source": [
    "# Model Building and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9126f8c7-b7e9-4ce2-9de4-89b07c763a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "model = SVC(kernel='linear')  # Linear kernel is common for text classification\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "989523e2-5984-4bd4-a309-f2e322f67592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Predictions\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c157836b-47b8-40d9-835b-f0a04d6f2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033a13e3-ce08-401e-8960-6cda38178d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2de0d5d2-a04d-4679-abf3-65f1b0e53a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.46%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88       493\n",
      "           1       0.87      0.91      0.89       547\n",
      "\n",
      "    accuracy                           0.88      1040\n",
      "   macro avg       0.89      0.88      0.88      1040\n",
      "weighted avg       0.89      0.88      0.88      1040\n",
      "\n",
      "Confusion Matrix:\n",
      " [[420  73]\n",
      " [ 47 500]]\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a5004b3-1e50-45ea-b1a3-e5cb772f3e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 90.67%\n",
      "Classification Report (Random Forest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       493\n",
      "           1       0.93      0.89      0.91       547\n",
      "\n",
      "    accuracy                           0.91      1040\n",
      "   macro avg       0.91      0.91      0.91      1040\n",
      "weighted avg       0.91      0.91      0.91      1040\n",
      "\n",
      "Confusion Matrix (Random Forest):\n",
      " [[454  39]\n",
      " [ 58 489]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(\"Classification Report (Random Forest):\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix (Random Forest):\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce2620-70b6-40a4-98b7-822c2bab97e1",
   "metadata": {},
   "source": [
    "# Sarcasm Detection System Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57a19e80-37a8-496b-8969-92c40ba71fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sarcasm(new_headline):\n",
    "    clean_headline=clean_text_advanced(new_headline)\n",
    "    transformed_headline=tfidf.transform([clean_headline])\n",
    "    prediction = model.predict(transformed_headline)\n",
    "\n",
    "    if prediction == 1:\n",
    "        return \"Sarcastic\"\n",
    "    else:\n",
    "        return \"Not Sarcastic\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d4130fb-b72f-4e5f-b57a-a111eb4477c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for comment: 'Oh great, another Monday! I just love waking up early after the weekend.' -> \n",
      " Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "# Example usage of detection system\n",
    "test_headline = \"Oh great, another Monday! I just love waking up early after the weekend.\"\n",
    "\n",
    "print(f\"Prediction for comment: '{test_headline}' -> \\n {detect_sarcasm(test_headline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6f06e55-2d37-459f-bd58-c63c9a7833bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for comment: 'Oh, how thoughtful! I really needed someone to explain the obvious to me.' -> \n",
      " Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "# Example usage of detection system\n",
    "test_headline = \"Oh, how thoughtful! I really needed someone to explain the obvious to me.\"\n",
    "print(f\"Prediction for comment: '{test_headline}' -> \\n {detect_sarcasm(test_headline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926c5c0-a00f-4ee5-b53b-3caf47f31954",
   "metadata": {},
   "source": [
    "# save mode and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "031a6046-ffe9-4ce6-a9ba-c6d008797395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model,open(\"model.pkl\",'wb'))\n",
    "pickle.dump(tfidf,open(\"tfidf.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c692b-a7c6-475e-aa22-36d4b17c0e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
